Домашнее задание к занятию "10.1 Системы мониторинга»  

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя платформу для вычислений с выдачей текстовых отчётов, которые сохраняются на диск. 
Взаимодействие с платформой осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?

- Метрики загрузки CPU, RAM, IOPS - помогут выявить пролблемы с инфраструкторой;
- Количество inode - т.к. отчеты хранятся на диске;
- Другие метрики HDD: объем свободного пространства, количество операций в секунду на запись/чтение - помогут выявить проблемы с жесткими дисками системы;
- Метрики входящей/исходящей сетевой нагрузки;
- HTTP метрики: количество HTTP запросов, количество ошибок 4хх/5хх, количество положительных ответов 2хх/3хх, время отклика сервиса на запрос, время выполнения HTTP-запроса, время создания отчета
#
2. Менеджер продукта, посмотрев на ваши метрики, сказал, что ему непонятно, что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?

По данному вопросу можно предложить разработать SLA, SLO и SLI: количество 400х и 500х ошибок, время реагирования на эти ошибки и их исправление.

А с помощью полученных метрик можно показать общее состояние системы и ее загрузку, показать время доступности системы, количество ошибок по типам 4хх/5хх, количество 2хх ответов сервисов.
#
3. Вашей DevOps-команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики, в свою очередь, хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?

- В первую очередь, важно отметить агенты, которые доступны в большинстве Linux-дистрибутивов: rsyslog;
syslog-ng. Когда число администрируемых хостов не является большим, то вполне хватит syslog-ng в качестве централизованного хранилища для файлов логов (сообщения будут приниматься на 514 UDP-порт). Также syslog-ng может раскладывать сообщения по директориям в учетом источника (FQDN/IP-адреса, даты, сервиса и пр.). 
- сомописный скрипт сбора логов
- ELK: Стек продуктов Elasticsearch, Logstash, Kibana - требуется очень много ресурсов и умение настривать
- Graylog - решение работает из коробки, нужны минимальные настройки
- Octopussy — опенсорсное решение для работы с логами.
#
4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA = 99% по http-кодам ответов. 
Этот параметр вычисляется по формуле: summ_2xx_requests/summ_all_requests. Он не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

Формула не учитывает 3xx-ответы. Правильная будет:

SLI = (summ_2xx_requests + summ_3xx_requests) / summ_all_requests
#
5. Опишите основные плюсы и минусы pull и push систем мониторинга. В лекции практически не было сравнения, пришлось изучать тему самостоятельно

Я бы не стал выделять плюсы или минусы. Данные системы выбираются исходя из определенных критериев:

- **Время жизни приложения:** если приложение долгоживущее, то можно использовать оба подхода, а если короткоживущее, то тут только Push модели.
- **Связность приложения и сервиса метрик:** в случае Pull модели приложение и сервис метрик связаны минимально: приложение экспортирует произвольные метрики, система мониторинга их пуллит и сохраняет. Вопрос сбора метрик решается полностью за пределами программы. А в Push модели приложение должно знать куда отправлять метрики, иметь авторизационные ключи и так далее. При этом система мониторинга знает какие метрики будут поступать.
- **Доступность сервера снаружи:** Для Pull модели система мониторинга должна иметь возможность “достучаться” до приложения. Если оно за NATом, то использовать Pull становится сложно, ведь нужно как-то прокидывать порт.
У Push модели ситуация обратная и от этого более простая: достаточно добиться доступности центральной ноды с приложений.
- **Безопасность:** Для Pull желательно установить реверс-прокси, вроде nginx, чтобы запросы не шли напрямую в приложение, закрыть порт nginx хоста в файрволле для всех, кроме сервера мониторинга, настроить экспортёр так, чтобы его порт прослушивался только на 127.0.0.1 (если вы используете реверс-прокси). У Push модели всё проще и от этого безопаснее: главное, защитить центральную ноду так, чтобы только приложения могли к ней пробиться.
- **Обнаружение недоступности ноды:** у Pull модели максимально быстро узнаёте о недоступности, и у вас есть конкретные симптомы: соединение рвётся, таймаутит или nginx отдаёт 5XX ошибку, у Push модели придётся немного покопаться и выяснить конкретную причину: упал агент, весь сервер, неполадки с сетью или приложение вообще переехало.
- **Централизованная настройка:** У Pull модели все настройки хранятся на центральном сервере. У Push модели, как правило, данные о необходимых метриках раздаются с центральной ноды. Также, вам необходимо позаботиться о том, как доставить авторизационные ключи и настройки подключения в конфиги агентов.
- **Масштабирование:** у Pull модели стратегия сводится к установке всё более мощной центральной ноды, а когда дальнейший апгрейд становится неэффективным, то применяют горизонтальное масштабирование. Например, у Prometheus есть механизм federation  , когда одна нода может стянуть данные с другой. У Push модели агенты по определению распределены по нодам, и обычно нагрузка на центральную ноду всё равно меньше, чем при пуллинге. Но если мощностей перестаёт хватать, то у Zabbix, например, есть прокси  для горизонтального масштабирования.
#
6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus - Pull
    - TICK - Push
    - Zabbix - Push/Pull
    - VictoriaMetrics - Push/Pull
    - Nagios - Pull
#
7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

```bash
root@ubuntu-pc:/home/sergo/10.1/sandbox-master# docker ps
CONTAINER ID   IMAGE           COMMAND                  CREATED          STATUS         PORTS                                                                                                                             NAMES
1a35c872b8eb   chrono_config   "/entrypoint.sh chro…"   10 minutes ago   Up 3 minutes   0.0.0.0:8888->8888/tcp, :::8888->8888/tcp                                                                                         sandbox-master_chronograf_1
8ab529809436   telegraf        "/entrypoint.sh tele…"   10 minutes ago   Up 3 minutes   8092/udp, 8125/udp, 8094/tcp                                                                                                      sandbox-master_telegraf_1
46ae0559c81f   kapacitor       "/entrypoint.sh kapa…"   10 minutes ago   Up 3 minutes   0.0.0.0:9092->9092/tcp, :::9092->9092/tcp                                                                                         sandbox-master_kapacitor_1
06d91ddbdd9b   influxdb        "/entrypoint.sh infl…"   10 minutes ago   Up 3 minutes   0.0.0.0:8082->8082/tcp, :::8082->8082/tcp, 0.0.0.0:8086->8086/tcp, :::8086->8086/tcp, 0.0.0.0:8089->8089/udp, :::8089->8089/udp   sandbox-master_influxdb_1
root@ubuntu-pc:/home/sergo/10.1/sandbox-master# 
```

<img
  src="https://github.com/Serg2211/devops-netology/blob/main/dz/10-monitoring-01-base/images/1.png"
  alt="image 1.png"
  title="image 1.png"
  style="display: inline-block; margin: 0 auto; max-width: 600px">

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`
#
8. Перейдите в веб-интерфейс Chronograf (`http://localhost:8888`) и откройте вкладку `Data explorer`.

    - Нажмите на кнопку `Add a query`
    - Изучите вывод интерфейса и выберите БД `telegraf.autogen`
    - В `measurments` выберите mem->host->telegraf_container_id , а в `fields` выберите used_percent. 
    Внизу появится график утилизации оперативной памяти в контейнере telegraf.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. 
    Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации места на диске 
(disk->host->telegraf_container_id) из веб-интерфейса.

Сделал скриншот чего-то из веб-интерфейса

<img
  src="https://github.com/Serg2211/devops-netology/blob/main/dz/10-monitoring-01-base/images/2.png"
  alt="image 2.png"
  title="image 2.png"
  style="display: inline-block; margin: 0 auto; max-width: 600px">

#
9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

<img
  src="https://github.com/Serg2211/devops-netology/blob/main/dz/10-monitoring-01-base/images/3.png"
  alt="image 3.png"
  title="image 3.png"
  style="display: inline-block; margin: 0 auto; max-width: 600px">
